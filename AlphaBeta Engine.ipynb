{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f0bfed-1b68-4453-a388-370251173444",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from copy import deepcopy\n",
    "import random\n",
    "import chess\n",
    "from ChessWrapper import ChessWrapper\n",
    "import time\n",
    "import signal\n",
    "import chess.pgn\n",
    "from evaluation import *\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from stockfish import Stockfish\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6383a05-4d52-486d-8881-2be263e81048",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50915a7-547b-466d-bd42-27c00a702818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the regression-based static evaluation model\n",
    "lr_eval = pickle.load(open('lr_eval.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ededf131-9a57-4f78-8fcd-91753633e94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = lr_eval.coef_\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "features = ['tapered_eval', 'king_atk', 'mobility', 'pawn_shield', 'pawn_islands','doubled_pawns', 'passed_pawns']\n",
    "\n",
    "\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('coefficients')\n",
    "plt.show()\n",
    "\n",
    "for i in indices:\n",
    "    print(importances[i], features[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d5a67b-0c28-413f-8464-2e59464bfbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_eval(board):\n",
    "    \"\"\"\n",
    "    Return a static evaluation of the board using the lr_eval model.\n",
    "    \"\"\"\n",
    "    feat = create_features(board)\n",
    "    return lr_eval.predict(feat)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70575acd-ce15-4bfd-afa1-071c65c468ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alphabeta(depth, qdepth, board, alpha, beta, is_max, eval_func=tapered_eval):\n",
    "    \"\"\"\n",
    "    Return the alpha-beta value of a given board with a specified serach depth.\n",
    "\n",
    "    depth: the depth left to search for alpha-beta.\n",
    "    qdepth: the qsearch depth.\n",
    "    board: the current board\n",
    "    alpha: track white's current best value.\n",
    "    beta: track black's current best value.\n",
    "    is_max: True when it's white's turn, False when it's black's turn.\n",
    "    eval_func: the evaluation function to be used\n",
    "    \"\"\"\n",
    "    if board.is_checkmate():\n",
    "        return -24000 if is_max else 24000\n",
    "    # game is over but not checkmate, so it's a draw\n",
    "    elif board.is_game_over():\n",
    "        return 0\n",
    "        \n",
    "    if depth <= 0:\n",
    "        qsearch_val = qsearch(qdepth, board, alpha, beta, is_max, eval_func)\n",
    "        return qsearch_val\n",
    "\n",
    "    if is_max:\n",
    "        best_val = float('-inf')\n",
    "        moves = get_ordered_moves(board, board.get_legal_moves())\n",
    "        \n",
    "        for move in moves:\n",
    "                \n",
    "            board.push(move)\n",
    "            v = alphabeta(depth - 1, qdepth, board, alpha, beta, not is_max, eval_func)\n",
    "\n",
    "            if v > 23000: #checkmate threshold. Incentivize shorter checkmates (ex: M1 better than M5)\n",
    "                v -= 1\n",
    "            elif v < -23000:\n",
    "                v += 1\n",
    "                \n",
    "            best_val = max(best_val, v)\n",
    "            alpha = max(alpha, best_val)\n",
    "            board.pop()\n",
    "            if beta <= alpha:\n",
    "                break\n",
    "        return best_val\n",
    "    else:\n",
    "        best_val = float('+inf')\n",
    "        moves = get_ordered_moves(board, board.get_legal_moves())\n",
    "        for move in moves:\n",
    "            board.push(move)\n",
    "            v = alphabeta(depth - 1, qdepth, board, alpha, beta, not is_max, eval_func)\n",
    "            if v > 23000: #checkmate threshold. Incentivize shorter checkmates (ex: M1 better than M5)\n",
    "                v -= 1\n",
    "            elif v < -23000:\n",
    "                v += 1\n",
    "            best_val = min(best_val, v)\n",
    "            beta = min(beta, best_val)\n",
    "            board.pop()\n",
    "            if beta <= alpha:\n",
    "                break\n",
    "        return best_val\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a72f37-4939-45b7-8e12-eae5b5c171ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qsearch(qdepth, board, alpha, beta, is_max, eval_func):\n",
    "    \"\"\"\n",
    "    Return the quiescence search value of a given board.\n",
    "\n",
    "    qdepth: the max depth left to search in quiescence\n",
    "    board: the current board\n",
    "    alpha: track white's current best value.\n",
    "    beta: track black's current best value.\n",
    "    is_max: True when it's white's turn, False when it's black's turn.\n",
    "    eval_func: the evaluation function to be used\n",
    "    \"\"\"\n",
    "    if qdepth <= 0:\n",
    "        return alpha if is_max else beta\n",
    "    stand_pat = eval_func(board)\n",
    "    if is_max:\n",
    "        if stand_pat >= beta:\n",
    "            return beta\n",
    "        if stand_pat >= alpha:\n",
    "            alpha = stand_pat\n",
    "        moves = board.get_legal_moves()\n",
    "        captures = [move for move in moves if board.is_capture(move)]\n",
    "        ordered_captures = get_ordered_captures(board, captures)\n",
    "        \n",
    "        for move in ordered_captures:\n",
    "            board.push(move)\n",
    "            score = qsearch(qdepth - 1, board, alpha, beta, not is_max, eval_func)\n",
    "            board.pop()\n",
    "            if score >= beta:\n",
    "                return beta\n",
    "            if score > alpha:\n",
    "                alpha = score\n",
    "        return alpha\n",
    "    else:\n",
    "        if stand_pat <= alpha:\n",
    "            return alpha\n",
    "        if stand_pat <= beta:\n",
    "            beta = stand_pat\n",
    "        moves = board.get_legal_moves()\n",
    "        captures = [move for move in moves if board.is_capture(move)]\n",
    "        ordered_captures = get_ordered_captures(board, captures)\n",
    "        \n",
    "        for move in ordered_captures:\n",
    "            board.push(move)\n",
    "            score = qsearch(qdepth - 1, board, alpha, beta, not is_max, eval_func)\n",
    "            board.pop()\n",
    "            if score <= alpha:\n",
    "                return alpha # original: return score?\n",
    "            if score < beta:\n",
    "                beta = score\n",
    "        return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd834b2-fd12-4edf-b66d-0ba00d04e5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_move(board, depth, qdepth, eval_func=tapered_eval):\n",
    "    \"\"\"\n",
    "    Given a board, use alpha-beta search (with set depth, qdepth) to find the best move \n",
    "\n",
    "    board: the current position to search\n",
    "    depth: the desired search depth of alpha-beta\n",
    "    qdepth: the desired max search depth of quiescence\n",
    "    eval_func: the evaluation function to use\n",
    "    \"\"\"\n",
    "    is_max = (board.get_turn() == chess.WHITE)\n",
    "    best_val = float('-inf') if is_max else float('+inf')\n",
    "\n",
    "    if board.is_checkmate():\n",
    "        return (None, -24000) if is_max else (None, 24000)\n",
    "\n",
    "    # game is over but not checkmate, so it's a draw\n",
    "    elif board.is_game_over():\n",
    "        return (None, 0)\n",
    "    \n",
    "    moves = board.get_legal_moves()\n",
    "    best_move = moves[0]\n",
    "    for move in moves:\n",
    "        board.push(move)\n",
    "        move_val = alphabeta(depth - 1, qdepth, board, float('-inf'), float('+inf'), not is_max, eval_func=eval_func)\n",
    "\n",
    "        board.pop()\n",
    "        if is_max and move_val > best_val:\n",
    "            best_move = move\n",
    "            best_val = move_val\n",
    "        elif not is_max and move_val < best_val:\n",
    "            best_move = move\n",
    "            best_val = move_val\n",
    "    return best_move, best_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b579ae21-a127-4f7e-a479-c72f76f5adb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_play(depth=4, qdepth=6, eval_func=tapered_eval):\n",
    "    \"\"\"\n",
    "    Have alpha-beta play a game against itself on specified depth, quiescence max depth.\n",
    "    Return the outcome of the game, and a game object to extract the game's pgn.\n",
    "    \"\"\"\n",
    "    b = ChessWrapper()\n",
    "    game = chess.pgn.Game()\n",
    "    game.headers[\"Event\"] = \"depth \" + str(depth)\n",
    "    node = None\n",
    "    wtm = True\n",
    "    while True:\n",
    "        if b.is_game_over():\n",
    "            break\n",
    "        if wtm:\n",
    "            m, v = find_best_move(b, depth, qdepth, eval_func=eval_func)\n",
    "        else:\n",
    "            m, v = find_best_move(b, depth, qdepth, eval_func=eval_func)\n",
    "\n",
    "        print('move is: ' + str(b.san(m)) + ' | eval is: ' + str(v))\n",
    "        print('-' * 15)\n",
    "        b.push(m)\n",
    "        wtm = not wtm\n",
    "        if node is None:\n",
    "            node = game.add_variation(m)\n",
    "        else:\n",
    "            node = node.add_variation(m)\n",
    "        print(b)\n",
    "        print('-' * 15)\n",
    "    return b.outcome(), game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828a20fa-81bc-4a0b-8bfe-ec2c9c40f15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vs_person(wtm=True, depth=4, qdepth=6, eval_func=tapered_eval):\n",
    "    \"\"\"\n",
    "    Have alpha-beta play a game against human input.\n",
    "    \"\"\"\n",
    "    \n",
    "    b = ChessWrapper()\n",
    "    game = chess.pgn.Game()\n",
    "    game.headers[\"Event\"] = \"vs_person, depth \" + str(depth)\n",
    "    node = None\n",
    "\n",
    "    while True:\n",
    "        if b.is_game_over():\n",
    "            break\n",
    "        if wtm:\n",
    "            m, v = find_best_move(b, depth, qdepth, eval_func=eval_func)\n",
    "        else:\n",
    "            m = None\n",
    "            while m is None:\n",
    "                try:\n",
    "                    input_move = input('What is the next move? \\n')\n",
    "                    m = b.parse_san(input_move)\n",
    "                except Exception as e:\n",
    "                    m = None\n",
    "            v = None\n",
    "\n",
    "        print('move is: ' + str(b.san(m)) + ' | eval is: ' + str(v))\n",
    "        print('-' * 15)\n",
    "        b.push(m)\n",
    "        wtm = not wtm\n",
    "        if node is None:\n",
    "            node = game.add_variation(m)\n",
    "        else:\n",
    "            node = node.add_variation(m)\n",
    "        print(b)\n",
    "        print('-' * 15)\n",
    "    return b.outcome(), game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a590b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wtm = True means alpha beta moves first, and is white\n",
    "def vs_sf(elo=1400, depth=4, qdepth=6, wtm=True, fen=None, eval_func=tapered_eval):\n",
    "    \"\"\"\n",
    "    Have alpha-beta play against stockfish, return the outcome and a game object to extract the game's pgn.\n",
    "\n",
    "    elo: the desired ELO of stockfish\n",
    "    depth: the depth of alpha-beta search\n",
    "    qdepth: the max depth of quiescence search\n",
    "    wtm: True indicates alpha-beta plays first, and plays white, False indicates alpha-beta plays second, and plays black\n",
    "    fen: FEN string to set up custom starting position\n",
    "    eval_func: the evaluation function to be used\n",
    "    \"\"\"\n",
    "    if fen is None:\n",
    "        b = ChessWrapper()\n",
    "\n",
    "        sf = Stockfish('/opt/homebrew/Cellar/stockfish/16/bin/stockfish')\n",
    "        sf.set_elo_rating(elo)\n",
    "    else:\n",
    "        b = ChessWrapper(fen)\n",
    "        sf = Stockfish('/opt/homebrew/Cellar/stockfish/16/bin/stockfish')\n",
    "        sf.set_fen_position(fen)\n",
    "        sf.set_elo_rating(elo)\n",
    "    \n",
    "    game = chess.pgn.Game()\n",
    "    game.headers[\"Event\"] = \"sf elo: \" + str(elo) + ', depth: ' + str(depth) + ', qdepth: ' + str(qdepth)\n",
    "    \n",
    "    if fen is not None:\n",
    "        game.setup(fen)\n",
    "        \n",
    "    node = None\n",
    "\n",
    "    while True:\n",
    "        if b.is_game_over():\n",
    "            break\n",
    "        if wtm:\n",
    "            m, v = find_best_move(b, depth, qdepth, eval_func=eval_func)\n",
    "        else:\n",
    "            m, v = chess.Move.from_uci(sf.get_best_move()), None\n",
    "\n",
    "        b.push(m)\n",
    "        sf.make_moves_from_current_position([str(m)])\n",
    "        \n",
    "        \n",
    "        \n",
    "        if node is None:\n",
    "            node = game.add_variation(m)\n",
    "        else:\n",
    "            node = node.add_variation(m)\n",
    "        \n",
    "        wtm = not wtm\n",
    "    return b.outcome(), game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0e4311",
   "metadata": {},
   "outputs": [],
   "source": [
    "def est_elo(ab_depth=4, ab_qdepth=6, eval_func=tapered_eval):\n",
    "\n",
    "    \"\"\"\n",
    "    Estimate the ELO of alpha-beta.\n",
    "\n",
    "    ab_depth: the depth of alpha-beta being tested\n",
    "    ab_qdepth: the qdepth of alpha-beta being tested\n",
    "    eval_func: the evaluation function to be used\n",
    "    \"\"\"\n",
    "    \n",
    "    # sicilian (open), queen's indian, reti transposed to english\n",
    "    openings = [\n",
    "        'rnbqkb1r/pp2pppp/3p1n2/8/3NP3/8/PPP2PPP/RNBQKB1R w KQkq - 1 5',\n",
    "        'rn1qkb1r/p1pp1ppp/bp2pn2/8/2PP4/5NP1/PP2PP1P/RNBQKB1R w KQkq - 1 5',\n",
    "        'rnbqk2r/ppp1ppbp/3p1np1/8/2P1P3/2N2N2/PP1P1PPP/R1BQKB1R w KQkq - 0 5'\n",
    "    ]\n",
    "    \n",
    "    random.shuffle(openings)\n",
    "    \n",
    "    lo = 0\n",
    "    hi = 3200\n",
    "    \n",
    "    df = pd.DataFrame(columns = ['depth', 'qdepth', 'lo', 'hi', 'elo', 'outcome', 'game'])\n",
    "    \n",
    "    for i in range(5):\n",
    "        mid = (lo + hi) // 2\n",
    "        ab_score = 0\n",
    "        sf_score = 0\n",
    "        \n",
    "        # play 3 pairs\n",
    "        for i in range(3):\n",
    "            \n",
    "            print('-' * 15)\n",
    "            print(ab_depth, ab_qdepth, mid)\n",
    "            # alpha beta plays white\n",
    "            ab_white_oc, ab_white_game = vs_sf(elo=mid, depth=ab_depth, qdepth=ab_qdepth, wtm=True, fen=openings[i], eval_func=eval_func)\n",
    "            \n",
    "            if ab_white_oc.winner == chess.WHITE:\n",
    "                ab_score += 1\n",
    "            elif ab_white_oc.winner == chess.BLACK:\n",
    "                sf_score += 1\n",
    "            else:\n",
    "                ab_score += 0.5\n",
    "                sf_score += 0.5\n",
    "                \n",
    "            new_row = {'depth': ab_depth, 'qdepth': ab_qdepth, 'lo': lo, 'hi': hi, 'elo': mid, 'outcome': ab_white_oc.winner != chess.BLACK, 'game': ab_white_game}\n",
    "            df = df._append(new_row, ignore_index=True)\n",
    "            print(ab_white_oc)\n",
    "            \n",
    "            # if either player cuts off early, don't need to play the rest\n",
    "            if ab_score >= 3 or sf_score >= 3.5:\n",
    "                break\n",
    "                \n",
    "            print('-' * 15)\n",
    "            print(ab_depth, ab_qdepth, mid)\n",
    "                \n",
    "            # alpha beta plays black\n",
    "            ab_black_oc, ab_black_game = vs_sf(elo=mid, depth=ab_depth, qdepth=ab_qdepth, wtm=False, fen=openings[i], eval_func=eval_func)\n",
    "            \n",
    "            if ab_black_oc.winner == chess.BLACK:\n",
    "                ab_score += 1\n",
    "            elif ab_black_oc.winner == chess.WHITE:\n",
    "                sf_score += 1\n",
    "            else:\n",
    "                ab_score += 0.5\n",
    "                sf_score += 0.5\n",
    "                \n",
    "            new_row = {'depth': ab_depth, 'qdepth': ab_qdepth, 'lo': lo, 'hi': hi, 'elo': mid, 'outcome': ab_black_oc.winner != chess.WHITE, 'game': ab_black_game}\n",
    "            df = df._append(new_row, ignore_index=True)\n",
    "            print(ab_black_oc)\n",
    "            \n",
    "            # if either player cuts off early, don't need to play the rest\n",
    "            if ab_score >= 3 or sf_score >= 3.5:\n",
    "                break\n",
    "                \n",
    "        if ab_score >= 3:\n",
    "            lo = mid\n",
    "        else:\n",
    "            hi = mid\n",
    "            \n",
    "    return df, lo, hi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d15769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix q search depth, try alpha-beta depth 1, 2, 3, 4\n",
    "# use tapered evaluation\n",
    "\n",
    "df_results = pd.DataFrame(columns = ['depth', 'lo', 'hi'])\n",
    "df_games = pd.DataFrame(columns = ['depth', 'qdepth', 'lo', 'hi', 'elo', 'outcome', 'game'])\n",
    "\n",
    "for d in range(1, 5):\n",
    "    df, lo, hi = est_elo(ab_depth=d, ab_qdepth=6, eval_func=tapered_eval)\n",
    "    new_row = {'depth': d, 'lo': lo, 'hi': hi}\n",
    "    df_results = df_results._append(new_row, ignore_index=True)\n",
    "    df_games = pd.concat([df_games, df])\n",
    "    print(df_results)\n",
    "    print(df_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec0cce4-a636-477a-b0c5-a3ae33302dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix q search depth, try alpha-beta depth 1, 2, 3, 4\n",
    "# use static evaluation with extra features\n",
    "\n",
    "df_results2 = pd.DataFrame(columns = ['depth', 'lo', 'hi'])\n",
    "df_games2 = pd.DataFrame(columns = ['depth', 'qdepth', 'lo', 'hi', 'elo', 'outcome', 'game'])\n",
    "\n",
    "for d in range(1, 5):\n",
    "    df, lo, hi = est_elo(ab_depth=d, ab_qdepth=6, eval_func=reg_eval)\n",
    "    new_row = {'depth': d, 'lo': lo, 'hi': hi}\n",
    "    df_results2 = df_results2._append(new_row, ignore_index=True)\n",
    "    df_games2 = pd.concat([df_games2, df])\n",
    "    print(df_results)\n",
    "    print(df_games)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
