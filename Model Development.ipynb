{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cb9e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "from ChessWrapper import ChessWrapper\n",
    "from copy import deepcopy\n",
    "from evaluation import *\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d801d49a-d7db-4743-8453-f56b2ef92729",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525b6e47-0640-4b10-a1a8-41b558d19701",
   "metadata": {},
   "source": [
    "### Read in the evaluation dataset, parse it, and create the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b2ad0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_data = pd.read_csv('chessData2.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b99a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse checkmate (#) in Evaluation\n",
    "def parse_eval(ev):\n",
    "    # if checkmate, produce large evaluation\n",
    "    if ev[0] == '#':\n",
    "        ev = ev[1:] + '000'\n",
    "    ev = eval(ev)\n",
    "    return ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e459dcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_data['Evaluation'] = sf_data['Evaluation'].apply(parse_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae101c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_data.head(n=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a53c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(data_df):\n",
    "    features_df = pd.DataFrame()\n",
    "    counter = 0\n",
    "    for idx, row in data_df.iterrows():\n",
    "        board = ChessWrapper(row['FEN'])\n",
    "\n",
    "        b_atk, w_ps = king_safety(board, chess.WHITE)\n",
    "        w_atk, b_ps = king_safety(board, chess.BLACK)\n",
    "    \n",
    "        new_row = pd.DataFrame(\n",
    "            {\n",
    "                'FEN': row['FEN'],\n",
    "                'tapered_eval': [tapered_eval(board)],\n",
    "                'king_atk': [w_atk - b_atk],\n",
    "                'mobility' : [mobility(board)],\n",
    "                'pawn_shield': [w_ps - b_ps],\n",
    "                'pawn_islands' : [pawn_islands(board, chess.WHITE) - pawn_islands(board, chess.BLACK)],\n",
    "                'doubled_pawns' : [doubled_pawns(board, chess.WHITE) - doubled_pawns(board, chess.BLACK)],\n",
    "                'passed_pawns' : [passers(board, chess.WHITE) - passers(board, chess.BLACK)],\n",
    "                'sf_evaluation': row['Evaluation']\n",
    "            }\n",
    "        )\n",
    "\n",
    "        features_df = pd.concat([features_df, new_row])\n",
    "        counter += 1\n",
    "        if counter % 1000 == 0:\n",
    "            print(counter)\n",
    "    return features_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d9adee-ce7b-408e-9c33-3d25339a9fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_data = sf_data.sample(n=200000, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057c7527-833c-4dc0-8ed6-7b3ad23cc193",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    reg_feat = pd.read_csv('reg_feat.csv')\n",
    "    reg_feat = reg_feat.drop(columns=['Unnamed: 0'])\n",
    "except:\n",
    "    reg_feat = create_features(reg_data)\n",
    "    reg_feat.to_csv('reg_feat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9266558-c5bf-4696-a185-a16b05f9b454",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca92d9f-ae56-4782-a981-c1bf9a703d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_feat = reg_feat.drop(columns=['FEN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5882213-c311-4db1-bbd8-47917451b88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_feat.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d1e477-691c-4ada-a52b-5d805d5dd8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_feat['sf_evaluation'].quantile(.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5f64d9-7969-4440-90fc-dba6482f4cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_feat['sf_evaluation'].quantile(.98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b9099d-e90d-4158-96ac-c8c248c2e35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_feat['sf_evaluation'] = reg_feat['sf_evaluation'].clip(lower=-1500, upper=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1f5a1a-4acb-43f2-ba23-f5e09771c2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_feat['tapered_eval'] = reg_feat['tapered_eval'].clip(lower=-1500, upper=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f068946-331b-4562-a28c-b7eb30d74e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try squared features\n",
    "reg_feat['mobility_2'] = np.square(reg_feat['mobility']) * np.sign(reg_feat['mobility'])\n",
    "reg_feat['pawn_islands_2'] = np.square(reg_feat['pawn_islands']) * np.sign(reg_feat['pawn_islands'])\n",
    "reg_feat['doubled_pawns_2'] = np.square(reg_feat['doubled_pawns']) * np.sign(reg_feat['doubled_pawns'])\n",
    "reg_feat['passed_pawns_2'] = np.square(reg_feat['passed_pawns']) * np.sign(reg_feat['passed_pawns'])\n",
    "reg_feat['pawn_shield_2'] = np.square(reg_feat['pawn_shield']) * np.sign(reg_feat['pawn_shield'])\n",
    "reg_feat['king_atk_2'] = np.square(reg_feat['king_atk']) * np.sign(reg_feat['king_atk'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65a9c5b-f98b-4247-bd3c-682bedfda47a",
   "metadata": {},
   "source": [
    "### Run Linear Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34884ed-3ab9-4339-a899-5147536c75c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b248a3-6ee5-4898-b8e9-377f7d422170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try all features\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(reg_feat.drop(columns='sf_evaluation'), reg_feat['sf_evaluation'], test_size=.25, random_state=42)\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "y_train_pred_linreg = lin_reg.predict(X_train_reg)\n",
    "y_test_pred_linreg = lin_reg.predict(X_test_reg)\n",
    "\n",
    "print(mean_absolute_error(y_train_reg, y_train_pred_linreg))\n",
    "print(mean_absolute_error(y_test_reg, y_test_pred_linreg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5ee2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X_train_reg.columns.values\n",
    "\n",
    "importances = lin_reg.coef_\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('coefficients')\n",
    "plt.show()\n",
    "\n",
    "for i in indices:\n",
    "    print(importances[i], features[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ddadde-b46a-4fae-aa7f-936a6f480018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use only the degree 2 features\n",
    "reg_feat2 = reg_feat.drop(columns=['mobility', 'king_atk', 'pawn_shield', 'passed_pawns','doubled_pawns', 'pawn_islands'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6de5721-13bf-4492-a4a1-5c9907bbc85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use only the degree 1 features\n",
    "reg_feat1 = reg_feat.drop(columns=['mobility_2', 'king_atk_2', 'pawn_shield_2', 'passed_pawns_2','doubled_pawns_2', 'pawn_islands_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec68beb2-38fe-4e42-993c-fc92f47125b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on only degree 2 features\n",
    "X_train_reg2, X_test_reg2, y_train_reg2, y_test_reg2 = train_test_split(reg_feat2.drop(columns='sf_evaluation'), reg_feat2['sf_evaluation'], test_size=.25, random_state=42)\n",
    "\n",
    "\n",
    "lin_reg2 = LinearRegression()\n",
    "\n",
    "lin_reg2.fit(X_train_reg2, y_train_reg2)\n",
    "\n",
    "\n",
    "y_train_pred_linreg2 = lin_reg2.predict(X_train_reg2)\n",
    "y_test_pred_linreg2 = lin_reg2.predict(X_test_reg2)\n",
    "\n",
    "\n",
    "print(mean_absolute_error(y_train_reg2, y_train_pred_linreg2))\n",
    "print(mean_absolute_error(y_test_reg2, y_test_pred_linreg2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e754182-0116-41c9-a94e-b4bb9bfd4918",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_squared_error(y_train_reg2, y_train_pred_linreg2))\n",
    "print(mean_squared_error(y_test_reg2, y_test_pred_linreg2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf8152a",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = lin_reg2.coef_\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "features = X_train_reg2.columns.values\n",
    "\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('coefficients')\n",
    "plt.show()\n",
    "\n",
    "for i in indices:\n",
    "    print(importances[i], features[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b40aa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try only the degree 1 features\n",
    "X_train_reg1, X_test_reg1, y_train_reg1, y_test_reg1 = train_test_split(reg_feat1.drop(columns='sf_evaluation'), reg_feat1['sf_evaluation'], test_size=.25, random_state=42)\n",
    "\n",
    "\n",
    "lin_reg1 = LinearRegression()\n",
    "\n",
    "lin_reg1.fit(X_train_reg1, y_train_reg1)\n",
    "\n",
    "\n",
    "y_train_pred_linreg1 = lin_reg1.predict(X_train_reg1)\n",
    "y_test_pred_linreg1 = lin_reg1.predict(X_test_reg1)\n",
    "\n",
    "\n",
    "print(mean_absolute_error(y_train_reg1, y_train_pred_linreg1))\n",
    "print(mean_absolute_error(y_test_reg1, y_test_pred_linreg1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea3e2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = lin_reg1.coef_\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "features = X_train_reg1.columns.values\n",
    "\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('coefficients')\n",
    "plt.show()\n",
    "\n",
    "for i in indices:\n",
    "    print(importances[i], features[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f5344e-739f-457c-8abb-fcd26d38ae77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the linear regression model\n",
    "pickle.dump(lin_reg1, open('lr_eval.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b49340",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_reg1.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2b5520-00c9-4ae7-b4c4-d7f8bcd6d543",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reg1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6554b0a2-de5d-4d3b-849e-fc06334683e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_squared_error(X_train_reg1['tapered_eval'], y_train_reg1))\n",
    "print(mean_squared_error(X_test_reg1['tapered_eval'], y_test_reg1))\n",
    "\n",
    "print(mean_absolute_error(X_train_reg1['tapered_eval'], y_train_reg1))\n",
    "print(mean_absolute_error(X_test_reg1['tapered_eval'], y_test_reg1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
